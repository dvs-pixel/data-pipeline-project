# ğŸ“Š Data Pipeline Development Project

This project focuses on building an automated data pipeline using Python, Pandas, and Scikit-Learn. The pipeline performs ETL (Extract, Transform, Load) operations on the Telco Customer Churn dataset to prepare it for machine learning or analytics tasks.

## ğŸ“ Project Structure

data_pipeline_project/
â”‚
â”œâ”€â”€ data/ # Raw dataset
â”‚ â””â”€â”€ projectdata.csv
â”‚
â”œâ”€â”€ processed_data/ # Cleaned/Transformed dataset
â”‚ â””â”€â”€ processed_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ data_pipeline_etl.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ etl_pipeline.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

###  **Dataset**
```md
## ğŸ§¾ Dataset

- **Name:** Telco Customer Churn dataset  
- **Location:** `data/projectdata.csv`  

## ğŸ›  Tools & Libraries

- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib / Seaborn
- Jupyter Notebook / VS Code

## âš™ï¸ ETL Pipeline Steps

1. **Extract:** Load CSV data using Pandas  
2. **Transform:** 
   - Handle missing values  
   - Encode categorical variables  
   - Normalize / scale numerical data  
3. **Load:** Save the processed data into `processed_data/processed_data.csv`

## ğŸ“ˆ Sample Visualizations

- Distribution of Churned vs Non-Churned customers  
- Correlation heatmap  
- Feature distributions  
- Countplots for categorical features  


## ğŸš€ How to Run

1. Clone the repository:
```bash
git clone https://github.com/your-username/data-pipeline-project.git

2. Install dependencies:
pip install -r requirements.txt

3. Run the script:
python scripts/etl_pipeline.py


---

###  **Author**
```md
## ğŸ‘¤ Author

- **Ankit Garg**  
- GitHub: [dvs-pixel](https://github.com/dvs-pixel)

